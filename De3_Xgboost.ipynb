{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mover_archivos_a_plagiados(archivos_plagiados, ruta_carpeta_origen, ruta_carpeta_destino):\n",
    "    if not os.path.exists(ruta_carpeta_destino):  # Crear carpeta en caso de que no exista\n",
    "        os.makedirs(ruta_carpeta_destino)\n",
    "\n",
    "    # Mover los archivos a la carpeta de destino\n",
    "    for archivo in archivos_plagiados:\n",
    "        ruta_origen = os.path.join(ruta_carpeta_origen, archivo)\n",
    "        ruta_destino = os.path.join(ruta_carpeta_destino, archivo)\n",
    "        \n",
    "        # Checar si el archivo ya se encuentra en el lugar\n",
    "        if os.path.exists(ruta_destino):\n",
    "            print(f\"El archivo '{archivo}' ya existe en '{ruta_carpeta_destino}', se omitirá.\")\n",
    "            continue\n",
    "        \n",
    "        shutil.move(ruta_origen, ruta_destino)\n",
    "        print(f\"Archivo '{archivo}' movido a '{ruta_carpeta_destino}'.\")\n",
    "\n",
    "# Lista de nombres de archivos plagiados proporcionada\n",
    "archivos_plagiados = [\n",
    "    \"003.java\", \"004.java\", \"005.java\", \"006.java\", \"008.java\", \"010.java\",\n",
    "    \"014.java\", \"021.java\", \"015.java\", \"023.java\", \"016.java\", \"024.java\",\n",
    "    \"017.java\", \"022.java\", \"030.java\", \"032.java\", \"033.java\", \"034.java\",\n",
    "    \"042.java\", \"044.java\", \"043.java\", \"251.java\", \"045.java\", \"047.java\",\n",
    "    \"048.java\", \"051.java\", \"183.java\", \"257.java\", \"258.java\", \"049.java\",\n",
    "    \"050.java\", \"052.java\", \"053.java\", \"059.java\", \"159.java\", \"250.java\",\n",
    "    \"061.java\", \"216.java\", \"062.java\", \"064.java\", \"069.java\", \"070.java\",\n",
    "    \"078.java\", \"079.java\", \"084.java\", \"085.java\", \"086.java\", \"087.java\",\n",
    "    \"155.java\", \"222.java\", \"242.java\", \"243.java\", \"089.java\", \"090.java\",\n",
    "    \"094.java\", \"098.java\", \"101.java\", \"212.java\", \"103.java\", \"105.java\",\n",
    "    \"106.java\", \"111.java\", \"107.java\", \"108.java\", \"112.java\", \"113.java\",\n",
    "    \"117.java\", \"119.java\", \"131.java\", \"133.java\", \"135.java\", \"174.java\",\n",
    "    \"136.java\", \"173.java\", \"137.java\", \"171.java\", \"140.java\", \"142.java\",\n",
    "    \"143.java\", \"145.java\", \"146.java\", \"147.java\", \"148.java\", \"150.java\",\n",
    "    \"153.java\", \"158.java\", \"161.java\", \"175.java\", \"180.java\", \"181.java\",\n",
    "    \"182.java\", \"185.java\", \"188.java\", \"190.java\", \"191.java\", \"193.java\",\n",
    "    \"195.java\", \"218.java\", \"201.java\", \"209.java\", \"202.java\", \"208.java\",\n",
    "    \"211.java\", \"221.java\", \"224.java\", \"228.java\", \"230.java\", \"232.java\",\n",
    "    \"233.java\", \"235.java\", \"237.java\", \"238.java\", \"240.java\", \"244.java\",\n",
    "    \"246.java\"\n",
    "]\n",
    "\n",
    "# Ruta de la carpeta compartida que contiene los archivos de código fuente\n",
    "ruta_carpeta_origen = '.\\\\archivos\\\\no_plagiados'\n",
    "\n",
    "# Ruta de la carpeta donde se moverán los archivos plagiados\n",
    "ruta_carpeta_destino = '.\\\\archivos\\\\plagiados'\n",
    "\n",
    "# Llamar a la función para mover los archivos\n",
    "mover_archivos_a_plagiados(archivos_plagiados, ruta_carpeta_origen, ruta_carpeta_destino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer archivos de código fuente y tokenizarlos\n",
    "def leer_y_tokenizar_archivo(ruta):\n",
    "    with open(ruta, 'r') as archivo:\n",
    "        code = archivo.read()\n",
    "\n",
    "    # Tokenización utilizando NLTK\n",
    "    tokens = nltk.word_tokenize(code)\n",
    "\n",
    "    return tokens, os.path.basename(ruta)  # Devolver también el nombre del archivo\n",
    "\n",
    "# Ruta de la carpeta de entrenamiento que contiene dos subcarpetas: plagiados y no plagiados\n",
    "ruta_carpeta_entrenamiento = '.\\\\archivos'\n",
    "\n",
    "# Leer archivos de código fuente de la carpeta de entrenamiento y tokenizarlos\n",
    "datos_entrenamiento = []\n",
    "for etiqueta, carpeta in enumerate([\"no_plagiados\", \"plagiados\"]):\n",
    "    ruta_carpeta = os.path.join(ruta_carpeta_entrenamiento, carpeta)\n",
    "    for archivo in os.listdir(ruta_carpeta):\n",
    "        if archivo.endswith(\".java\"):\n",
    "            ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "            tokens, nombre_archivo = leer_y_tokenizar_archivo(ruta_archivo)\n",
    "            datos_entrenamiento.append((tokens, etiqueta, nombre_archivo))  # Agrega los tokens, su etiqueta y el nombre del archivo\n",
    "\n",
    "# Separar datos en características (X), etiquetas (y) y nombres de archivo\n",
    "X = [(tokens, nombre_archivo) for tokens, _, nombre_archivo in datos_entrenamiento]\n",
    "y = [etiqueta for _, etiqueta, _ in datos_entrenamiento]\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "#, random_state=42\n",
    "# Convertir las listas de tokens en cadenas de texto\n",
    "X_train_text = [' '.join(tokens) for tokens, _ in X_train]\n",
    "X_val_text = [' '.join(tokens) for tokens, _ in X_val]\n",
    "\n",
    "# Inicializar el vectorizador TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Ajustar el vectorizador y transformar los datos de entrenamiento\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
    "\n",
    "# Transformar los datos de validación utilizando el mismo vectorizador\n",
    "X_val_tfidf = vectorizer.transform(X_val_text)\n",
    "\n",
    "# Definir y entrenar el modelo XGBoost\n",
    "modelo = xgb.XGBClassifier()\n",
    "modelo.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predecir etiquetas para el conjunto de validación\n",
    "y_val_pred = modelo.predict(X_val_tfidf)\n",
    "\n",
    "# Calcular la precisión y la recuperación en el conjunto de validación\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recuperacion = recall_score(y_val, y_val_pred)\n",
    "\n",
    "print(\"Precisión en el conjunto de validación:\", precision)\n",
    "print(\"Recuperación en el conjunto de validación:\", recuperacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener algunas predicciones para la visualización\n",
    "num_instancias_visualizacion = 259\n",
    "instancias_visualizacion = list(zip(X_val_text[:num_instancias_visualizacion], X_val[:num_instancias_visualizacion], y_val[:num_instancias_visualizacion], y_val_pred[:num_instancias_visualizacion]))\n",
    "\n",
    "# Imprimir las instancias de visualización con etiquetas reales y predichas\n",
    "print(\"Instancias de visualización:\")\n",
    "for i, (texto, (_, nombre_archivo), etiqueta_real, etiqueta_predicha) in enumerate(instancias_visualizacion, start=1):\n",
    "    print(f\"Instancia {i}:\")\n",
    "    print(\"Nombre del Archivo:\", nombre_archivo)\n",
    "    print(\"Texto:\")\n",
    "    print(texto)\n",
    "    print(\"Etiqueta Real:\", etiqueta_real)\n",
    "    print(\"Etiqueta Predicha:\", etiqueta_predicha)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo entrenado\n",
    "modelo.save_model(\"plagio_xgboost.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 00af3420.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 00c0b82a.java\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 0b04b41e.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 0c1143f7.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 0c9d4def.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 1ea771ea.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 2a35cd81.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 2a655afe.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 3e6def38.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 4fb09c5f.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 548ffb07.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo 692a4496.java\n",
      "Error de sintaxis: \n",
      "No se pudo construir el AST para el archivo c4ca2ff3.java\n",
      "Archivos similares:\n",
      "- 11c2ab99.java y bdfe8110.java (Similitud de coseno: 1.00, Similitud de Jaccard: 0.98)\n",
      "- 4da08761.java y 5449d33c.java (Similitud de coseno: 0.99, Similitud de Jaccard: 0.72)\n",
      "- 4da08761.java y 9291ca83.java (Similitud de coseno: 0.98, Similitud de Jaccard: 0.68)\n",
      "- 4da08761.java y fdd41565.java (Similitud de coseno: 0.98, Similitud de Jaccard: 0.68)\n",
      "- 5449d33c.java y 86102d81.java (Similitud de coseno: 0.99, Similitud de Jaccard: 0.81)\n",
      "- 5449d33c.java y 97a7fab5.java (Similitud de coseno: 0.98, Similitud de Jaccard: 0.72)\n",
      "- a4d6775d.java y cb87df79.java (Similitud de coseno: 0.98, Similitud de Jaccard: 0.76)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import javalang\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def leer_archivo(archivo):\n",
    "    with open(archivo, 'r') as f:\n",
    "        lineas = f.readlines()\n",
    "        contenido = ''.join([linea for linea in lineas if not linea.strip().startswith(\"import\")]).replace('\\n', '')\n",
    "    return contenido\n",
    "\n",
    "def limpiar_codigo(codigo):\n",
    "    codigo = re.sub(r'//.*?\\n|/\\*.*?\\*/', '', codigo, flags=re.DOTALL)\n",
    "    codigo = re.sub(r'\\s+', ' ', codigo)\n",
    "    codigo = re.sub(r'\\n\\s+', '\\n', codigo)\n",
    "    return codigo\n",
    "\n",
    "def construir_ast(codigo):\n",
    "    try:\n",
    "        return javalang.parse.parse(codigo)\n",
    "    except javalang.parser.JavaSyntaxError as e:\n",
    "        print(\"Error de sintaxis:\", e)\n",
    "\n",
    "def obtener_archivos_java(ruta_carpeta):\n",
    "    return [archivo for archivo in os.listdir(ruta_carpeta) if archivo.endswith(\".java\")]\n",
    "\n",
    "ruta_carpeta = \".\\\\CFiles\\\\java\\\\train\"\n",
    "archivos_java = obtener_archivos_java(ruta_carpeta)\n",
    "arboles = {}\n",
    "\n",
    "for archivo in archivos_java:\n",
    "    ruta_archivo = os.path.join(ruta_carpeta, archivo)\n",
    "    contenido_archivo = leer_archivo(ruta_archivo)\n",
    "    arbol_sintactico = construir_ast(contenido_archivo)\n",
    "    if arbol_sintactico:\n",
    "        arboles[archivo] = limpiar_codigo(str(arbol_sintactico))\n",
    "    else:\n",
    "        print(\"No se pudo construir el AST para el archivo\", archivo)\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "documentos = [arbol for arbol in arboles.values()]\n",
    "nombres_archivos = list(arboles.keys())\n",
    "tfidf_matrix = vectorizer.fit_transform(documentos)\n",
    "similarity_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "umbral_similitud_cosine = 0.98\n",
    "umbral_similitud_jaccard = 0.5\n",
    "\n",
    "archivos_similares = []\n",
    "\n",
    "print(\"Archivos similares:\")\n",
    "for i, nombre_archivo1 in enumerate(nombres_archivos):\n",
    "    for j, nombre_archivo2 in enumerate(nombres_archivos):\n",
    "        if i < j and similarity_matrix[i, j] >= umbral_similitud_cosine:\n",
    "            tokens1 = set(re.findall(r'\\b\\w+\\b', arboles[nombre_archivo1]))\n",
    "            tokens2 = set(re.findall(r'\\b\\w+\\b', arboles[nombre_archivo2]))\n",
    "            similitud_jaccard = len(tokens1.intersection(tokens2)) / len(tokens1.union(tokens2))\n",
    "            if similitud_jaccard >= umbral_similitud_jaccard:\n",
    "                archivos_similares.append((nombre_archivo1, nombre_archivo2))\n",
    "                print(f\"- {nombre_archivo1} y {nombre_archivo2} (Similitud de coseno: {similarity_matrix[i, j]:.2f}, Similitud de Jaccard: {similitud_jaccard:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados:\n",
      "Falsos positivos: 2\n",
      "Falsos negativos: 115\n",
      "Aciertos: 41\n"
     ]
    }
   ],
   "source": [
    "archivos_plagiados = [\n",
    "    \"003.java\", \"004.java\", \"005.java\", \"006.java\", \"008.java\", \"010.java\",\n",
    "    \"014.java\", \"021.java\", \"015.java\", \"023.java\", \"016.java\", \"024.java\",\n",
    "    \"017.java\", \"022.java\", \"030.java\", \"032.java\", \"033.java\", \"034.java\",\n",
    "    \"042.java\", \"044.java\", \"043.java\", \"251.java\", \"045.java\", \"047.java\",\n",
    "    \"048.java\", \"051.java\", \"183.java\", \"257.java\", \"258.java\", \"049.java\",\n",
    "    \"050.java\", \"052.java\", \"053.java\", \"059.java\", \"159.java\", \"250.java\",\n",
    "    \"061.java\", \"216.java\", \"062.java\", \"064.java\", \"069.java\", \"070.java\",\n",
    "    \"078.java\", \"079.java\", \"084.java\", \"085.java\", \"086.java\", \"087.java\",\n",
    "    \"155.java\", \"222.java\", \"242.java\", \"243.java\", \"089.java\", \"090.java\",\n",
    "    \"094.java\", \"098.java\", \"101.java\", \"212.java\", \"103.java\", \"105.java\",\n",
    "    \"106.java\", \"111.java\", \"107.java\", \"108.java\", \"112.java\", \"113.java\",\n",
    "    \"117.java\", \"119.java\", \"131.java\", \"133.java\", \"135.java\", \"174.java\",\n",
    "    \"136.java\", \"173.java\", \"137.java\", \"171.java\", \"140.java\", \"142.java\",\n",
    "    \"143.java\", \"145.java\", \"146.java\", \"147.java\", \"148.java\", \"150.java\",\n",
    "    \"153.java\", \"158.java\", \"161.java\", \"175.java\", \"180.java\", \"181.java\",\n",
    "    \"182.java\", \"185.java\", \"188.java\", \"190.java\", \"191.java\", \"193.java\",\n",
    "    \"195.java\", \"218.java\", \"201.java\", \"209.java\", \"202.java\", \"208.java\",\n",
    "    \"211.java\", \"221.java\", \"224.java\", \"228.java\", \"230.java\", \"232.java\",\n",
    "    \"233.java\", \"235.java\", \"237.java\", \"238.java\", \"240.java\", \"244.java\",\n",
    "    \"246.java\"\n",
    "]\n",
    "\n",
    "# Contar los diferentes tipos de resultados\n",
    "falsos_positivos = len([par for par in archivos_similares if par[0] not in archivos_plagiados and par[1] in archivos_plagiados])\n",
    "falsos_negativos = len([archivo in archivos_plagiados for archivo in archivos_plagiados])\n",
    "verdaderos_positivos = len(archivos_similares)\n",
    "\n",
    "print(\"Resultados:\")\n",
    "print(f\"Falsos positivos: {falsos_positivos}\")\n",
    "print(f\"Falsos negativos: {falsos_negativos}\")\n",
    "print(f\"Aciertos: {verdaderos_positivos}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
